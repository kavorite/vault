<h1 id="feature-wise-linear-modulation"><a aria-hidden="true" class="anchor-heading icon-link" href="#feature-wise-linear-modulation"></a>Feature-wise Linear Modulation</h1>
<p><a href="https://arxiv.org/abs/1709.0771">FiLM</a>, or <strong>F</strong>eature-wise <strong>L</strong>inear <strong>M</strong>odulation (Perez, et al., 2017) is a method of injecting intermediate support information for a task into a visual feature extraction pipeline. This is accomplished by introducing a generator network which "modulates" feature-wise normalization parameters according to some continuous function conditioned on arbitrary data. Continuous 'modulations' of input samples were used in the original publication to condition neural networks on task specific information, sideloading semantically relevant 'queries.'</p>
<h2 id="applications"><a aria-hidden="true" class="anchor-heading icon-link" href="#applications"></a>Applications</h2>
<p><a href="https://arxiv.org/abs/1709.0771">FiLM</a> has proven useful in training DNNs to fit to <a href="/vault/notes/0oj3xw4fhwwb7qifcve8g19">multiple objective functions simultaneously</a>, such that the tradeoff between objectives can be adjusted at inference-time, and in <a href="https://arxiv.org/abs/2206.00050">deep ensembling</a> (Turkoglu et al., 2022), where multiple sets of normalization parameters can be learned in order to emulate multiple instantiations of a given model while sharing the rest of the parameter set. A forward pass is required for each set of learned "feature modulations," but the additional performance gains come at a predetermined, fixed-parameter cost. </p>
<hr>
<strong>Backlinks</strong>
<ul>
<li><a href="/vault/notes/kxklakzrojw3q2r808mzh65">Continuous Kernel Convolution (vault)</a></li>
<li><a href="/vault/notes/s2dvzt8effhbjxgsflxlw75">UnCLIP (vault)</a></li>
<li><a href="/vault/notes/0oj3xw4fhwwb7qifcve8g19">Loss Conditioning (vault)</a></li>
<li><a href="/vault/notes/txmy1anxf7bhr607yyk7te7">DEQ Extensions (vault)</a></li>
</ul>