<h1 id="momentum-contrast"><a aria-hidden="true" class="anchor-heading icon-link" href="#momentum-contrast"></a>Momentum Contrast</h1>
<p>Introduced by He, et al., 2019, <strong>Mo</strong>mentum <strong>Co</strong>ntrast or MoCo, uses a set of "slow" and "fast" parameters. A "slow" momentum encoder, with a small update rate of ρ ≤ 0.01, is interpolated toward the latest parameter vector at each descent step, and to perform self-supervised instance discrimination, its embeddings are used as supervisory signals. Like <a href="/vault/notes/9cismp3jsqbqx1pyso6xdc4">Supervised Contrastive Learning</a>, it required large training batches, which its authors would attempt to rectify in MoCov2.</p>
<h2 id="derivatives"><a aria-hidden="true" class="anchor-heading icon-link" href="#derivatives"></a>Derivatives</h2>
<h3 id="mocov2"><a aria-hidden="true" class="anchor-heading icon-link" href="#mocov2"></a><a href="https://arxiv.org/abs/2003.04297">MoCov2</a></h3>
<p>Introduced by (Chen et al., 2020), the momentum encoder is used to enqueue old embeddings to gradually build a "dictionary" of negative samples, pushing future representations away from the past. An MLP projection head and stronger data augmentations were used. </p>
<p><img src="/vault/assets/images/mocov2.png" alt="MoCov2"> </p>
<h3 id="simmoco-and-simco"><a aria-hidden="true" class="anchor-heading icon-link" href="#simmoco-and-simco"></a><a href="https://arxiv.org/abs/2203.17248">SimMoCo and SimCo</a></h3>
<p>Zhang, et al., 2022 eschew MoCov2's addition of a "negative dictionary" in favor of a "dual-temperature" approach. Their publication also contains a helpful rundown of the wider self-supervised contrastive literature (Section 7, "A Unified Perspective on SSL and Beyond").</p>
<h3 id="fast-moco"><a aria-hidden="true" class="anchor-heading icon-link" href="#fast-moco"></a><a href="https://arxiv.org/abs/2207.08220">Fast-MoCo</a></h3>
<p>This method, published by Ci et al., 2022, bears some resemblance to <a href="/vault/notes/d2ujohiat60fr3984ndteed">Fast Knowledge Distillation for CNNs</a> and FAIR's <a href="https://arxiv.org/abs/2104.14294">DINO</a> (<a href="https://ai.facebook.com/blog/dino-paws-computer-vision-with-self-supervised-transformers-and-10x-more-efficient-training/">blog</a>; Caron et al., 2021) with its self-supervised "collage assembly" objective, applying InfoNCE to multiple augmented views of a set of objects.</p>
<hr>
<hr>
<strong>Backlinks</strong>
<ul>
<li><a href="/vault/notes/jc56h8njgqawadlroex4ju1">Contrastive Learning (vault)</a></li>
<li><a href="/vault/notes/9cismp3jsqbqx1pyso6xdc4">Supervised Contrastive Learning (vault)</a></li>
<li><a href="/vault/notes/d2ujohiat60fr3984ndteed">Fast Knowledge Distillation for CNNs (vault)</a></li>
</ul>