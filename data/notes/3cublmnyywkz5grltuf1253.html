<h1 id="sharpness-aware-minimization"><a aria-hidden="true" class="anchor-heading icon-link" href="#sharpness-aware-minimization"></a>Sharpness Aware Minimization</h1>
<p><strong>S</strong>harpness <strong>A</strong>ware <strong>M</strong>inimization, or SAM, is a regularization technique introduced by <a href="https://arxiv.org/abs/2010.01412">Foret, et al., 2020</a> used to train models which have the same generalization ability under datasets that are up to an order of magnitude smaller. The algorithm is so simple I have <a href="https://github.com/kavorite/sam">implemented it myself,</a> and I can describe it here:</p>
<ol>
<li>Requirements:
<ol>
<li><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi><mo><mi mathvariant="normal">≔</mi></mo></mrow><annotation encoding="application/x-tex">V \coloneqq</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel"><span class="mrel"><span class="mop" style="position:relative;top:-0.0347em;">:</span></span><span class="mrel"><span class="mspace" style="margin-right:-0.0667em;"></span></span><span class="mrel">=</span></span></span></span></span></span> the set of model parameters <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mtext mathvariant="bold">w</mtext><mn>0</mn></msub><mo separator="true">,</mo><msub><mtext mathvariant="bold">w</mtext><mn>1</mn></msub><mo>…</mo><msub><mtext mathvariant="bold">w</mtext><mi>n</mi></msub></mrow><annotation encoding="application/x-tex">\textbf{w}_0, \textbf{w}_1\ldots \textbf{w}_n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6389em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord text"><span class="mord textbf">w</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord text"><span class="mord textbf">w</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord text"><span class="mord textbf">w</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span></li>
<li><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext mathvariant="bold">v</mtext><mo><mi mathvariant="normal">≔</mi></mo></mrow><annotation encoding="application/x-tex">\textbf{v} \coloneqq</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4444em;"></span><span class="mord text"><span class="mord textbf">v</span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel"><span class="mrel"><span class="mop" style="position:relative;top:-0.0347em;">:</span></span><span class="mrel"><span class="mspace" style="margin-right:-0.0667em;"></span></span><span class="mrel">=</span></span></span></span></span></span> global parameter vector (flatten/concat <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mtext mathvariant="bold">w</mtext><mi>i</mi></msub><mo>∈</mo><mi>V</mi></mrow><annotation encoding="application/x-tex">\textbf{w}_i \in V</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6891em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord text"><span class="mord textbf">w</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span></span></span></span></span>)</li>
<li><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ρ</mi><mo><mi mathvariant="normal">≔</mi></mo></mrow><annotation encoding="application/x-tex">\rho \coloneqq</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">ρ</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel"><span class="mrel"><span class="mop" style="position:relative;top:-0.0347em;">:</span></span><span class="mrel"><span class="mspace" style="margin-right:-0.0667em;"></span></span><span class="mrel">=</span></span></span></span></span></span> A hyperparameter. Authors usually set to 0.05.</li>
</ol>
</li>
<li>Until converged:
<ol>
<li>Take a small, <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ρ</mi></mrow><annotation encoding="application/x-tex">\rho</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord mathnormal">ρ</span></span></span></span></span>-sized ascent step:
<div class="math math-display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mtext mathvariant="bold">w</mtext><mi>i</mi></msub><mo>←</mo><msub><mtext mathvariant="bold">w</mtext><mi>i</mi></msub><mo>+</mo><mi>ρ</mi><mfrac><mrow><msub><mi mathvariant="normal">∇</mi><mi>L</mi></msub><msub><mtext mathvariant="bold">w</mtext><mi>i</mi></msub></mrow><mrow><mi mathvariant="normal">∣</mi><mi mathvariant="normal">∣</mi><mtext mathvariant="bold">v</mtext><mi mathvariant="normal">∣</mi><msub><mi mathvariant="normal">∣</mi><mn>2</mn></msub></mrow></mfrac><mtext> </mtext><mi mathvariant="normal">∀</mi><mtext> </mtext><msub><mtext mathvariant="bold">w</mtext><mi>i</mi></msub><mo>∈</mo><mi>V</mi></mrow><annotation encoding="application/x-tex">\textbf{w}_i \leftarrow \textbf{w}_i + \rho \frac {\nabla_{L}\textbf{w}_i} {||\textbf{v}||_2}\ \forall\ \textbf{w}_i \in V</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5944em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord text"><span class="mord textbf">w</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">←</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord text"><span class="mord textbf">w</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:2.2963em;vertical-align:-0.936em;"></span><span class="mord mathnormal">ρ</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3603em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">∣∣</span><span class="mord text"><span class="mord textbf">v</span></span><span class="mord">∣</span><span class="mord"><span class="mord">∣</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord">∇</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">L</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord text"><span class="mord textbf">w</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace"> </span><span class="mord">∀</span><span class="mspace"> </span><span class="mord"><span class="mord text"><span class="mord textbf">w</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.22222em;">V</span></span></span></span></span></div>
</li>
<li>Take an actual <em>descent</em> step using an "inner" optimizer, like SGD. This is typically more involved, but also better-studied (see review by <a href="https://arxiv.org/abs/1609.04747">Ruder, et al., 2016</a>).</li>
</ol>
</li>
</ol>
<p>To say nothing of how a more stable training regime helps address the ongoing replicability crisis in deep learning, using SAM also means less training time. </p>
<p>This means despite SAM's requirement of twice as much compute per forward-backward pass, in effect taking one step back for every step forward, the technique's uncanny ability to converge to a superior and more stable performance within half as many steps suggests that the method's sample efficiency offers some potential to help this method cut some costs despite itself, especially in terms of data procurement. <a href="https://arxiv.org/abs/2203.02714">LookSAM</a> can help offset those compute costs if you're pulling your hair out over it.</p>
<p><img src="/vault/assets/images/sam.png" alt="Left/Right: SGD/SA-SGD"></p>
<p>Left/Right: Visualizations of loss landscape surrounding trained ResNet, contrasting SGD/SA-SGD, from Foret, et al. Wider, deeper minima result in better calibrated models with more generalizable decision boundaries.</p>
<h2 id="derivatives-and-extensions"><a aria-hidden="true" class="anchor-heading icon-link" href="#derivatives-and-extensions"></a>Derivatives and Extensions</h2>
<h3 id="looksam"><a aria-hidden="true" class="anchor-heading icon-link" href="#looksam"></a><a href="https://arxiv.org/abs/2203.02714">LookSAM</a></h3>
<p>Liu, et al., 2022 use a projective approximation to compute the ascent gradient every <em>k</em> steps instead of re-computing it every time a step is taken. Shameless self-plug, my <a href="https://github.com/kavorite/sam">implementation</a> includes an interface to this functionality.</p>
<h3 id="asam"><a aria-hidden="true" class="anchor-heading icon-link" href="#asam"></a><a href="https://arxiv.org/abs/2102.11600">ASAM</a></h3>
<p><strong>A</strong>daptive SAM, introduced by Kwon, et al., 2021, re-weights the ascent directions by a more complex formula for each parameter norm rather than using the global norm. My <a href="https://github.com/kavorite/sam">implementation</a> also includes a variant of this.</p>
<h3 id="δ-sam"><a aria-hidden="true" class="anchor-heading icon-link" href="#δ-sam"></a><a href="https://arxiv.org/abs/2112.08772">δ-SAM</a></h3>
<p>SAM with dynamic reweighting by Zhou, et al., 2021— I'll be honest, I just stopped reading this one as soon as I saw it required doing three forward passes. </p>
<hr>
<strong>Backlinks</strong>
<ul>
<li><a href="/vault/notes/txmy1anxf7bhr607yyk7te7">DEQ Extensions (vault)</a></li>
</ul>