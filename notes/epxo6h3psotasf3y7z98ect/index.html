<!DOCTYPE html><html><head><meta name="viewport" content="width=device-width"/><meta charSet="utf-8"/><link rel="icon" href="/favicon.ico"/><title>MMASS</title><meta name="robots" content="index,follow"/><meta name="googlebot" content="index,follow"/><meta name="description" content="kavlogs"/><meta property="og:title" content="MMASS"/><meta property="og:description" content="kavlogs"/><meta property="og:url" content="https://kavorite.github.io/vault/notes/epxo6h3psotasf3y7z98ect/"/><meta property="og:type" content="article"/><meta property="article:published_time" content="7/27/2022"/><meta property="article:modified_time" content="7/27/2022"/><link rel="canonical" href="https://kavorite.github.io/vault/notes/epxo6h3psotasf3y7z98ect/"/><meta name="next-head-count" content="14"/><link rel="preload" href="/vault/_next/static/css/bec73badd4e5ba88.css" as="style"/><link rel="stylesheet" href="/vault/_next/static/css/bec73badd4e5ba88.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/vault/_next/static/chunks/polyfills-5cd94c89d3acac5f.js"></script><script src="/vault/_next/static/chunks/webpack-3af8c0cde089b23c.js" defer=""></script><script src="/vault/_next/static/chunks/framework-bb5c596eafb42b22.js" defer=""></script><script src="/vault/_next/static/chunks/main-34d019fcedb697b6.js" defer=""></script><script src="/vault/_next/static/chunks/pages/_app-b20c4be9bb651ea8.js" defer=""></script><script src="/vault/_next/static/chunks/826-e0e455fb469c158f.js" defer=""></script><script src="/vault/_next/static/chunks/986-737e5da213076068.js" defer=""></script><script src="/vault/_next/static/chunks/pages/notes/%5Bid%5D-00dd1421f3ce3a3e.js" defer=""></script><script src="/vault/_next/static/x67zoUTAB0zyGOxjfffun/_buildManifest.js" defer=""></script><script src="/vault/_next/static/x67zoUTAB0zyGOxjfffun/_ssgManifest.js" defer=""></script><script src="/vault/_next/static/x67zoUTAB0zyGOxjfffun/_middlewareManifest.js" defer=""></script></head><body><div id="__next" data-reactroot=""><section class="ant-layout" style="width:100%;min-height:100%"><header class="ant-layout-header" style="position:fixed;isolation:isolate;z-index:1;width:100%;border-bottom:1px solid #d4dadf;height:64px;padding:0 24px 0 2px"><div class="ant-row ant-row-center" style="max-width:992px;justify-content:space-between;margin:0 auto"><div style="display:flex" class="ant-col ant-col-xs-20 ant-col-sm-4"></div><div class="ant-col gutter-row ant-col-xs-0 ant-col-sm-20 ant-col-md-20 ant-col-lg-19"><div class="ant-select ant-select-lg ant-select-auto-complete ant-select-single ant-select-allow-clear ant-select-show-search" style="width:100%"><div class="ant-select-selector"><span class="ant-select-selection-search"><input type="search" autoComplete="off" class="ant-select-selection-search-input" role="combobox" aria-haspopup="listbox" aria-owns="undefined_list" aria-autocomplete="list" aria-controls="undefined_list" aria-activedescendant="undefined_list_0" value=""/></span><span class="ant-select-selection-placeholder">For full text search please use the &#x27;?&#x27; prefix. e.g. ? Onboarding</span></div></div></div><div style="display:none;align-items:center;justify-content:center" class="ant-col ant-col-xs-4 ant-col-sm-4 ant-col-md-0 ant-col-lg-0"><span role="img" aria-label="menu" style="font-size:24px" tabindex="-1" class="anticon anticon-menu"><svg viewBox="64 64 896 896" focusable="false" data-icon="menu" width="1em" height="1em" fill="currentColor" aria-hidden="true"><path d="M904 160H120c-4.4 0-8 3.6-8 8v64c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-64c0-4.4-3.6-8-8-8zm0 624H120c-4.4 0-8 3.6-8 8v64c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-64c0-4.4-3.6-8-8-8zm0-312H120c-4.4 0-8 3.6-8 8v64c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-64c0-4.4-3.6-8-8-8z"></path></svg></span></div></div></header><section class="ant-layout" style="margin-top:64px;display:flex;flex-direction:row"><div class="site-layout-sidebar" style="flex:0 0 auto;width:calc(max((100% - 992px) / 2, 0px) + 200px);min-width:200px;padding-left:calc((100% - 992px) / 2)"><aside class="ant-layout-sider ant-layout-sider-dark" style="position:fixed;overflow:auto;height:calc(100vh - 64px);background-color:transparent;flex:0 0 200px;max-width:200px;min-width:200px;width:200px"><div class="ant-layout-sider-children"></div></aside></div><section class="ant-layout side-layout-main" style="max-width:1200px;display:initial"><main class="ant-layout-content main-content" role="main" style="padding:0 24px"><div class="ant-row"><div class="ant-col ant-col-24"><div class="ant-row" style="margin-left:-10px;margin-right:-10px"><div style="padding-left:10px;padding-right:10px" class="ant-col ant-col-xs-24 ant-col-md-18"><div><h1 id="mmass"><a aria-hidden="true" class="anchor-heading icon-link" href="#mmass"></a>MMASS</h1>
<p><a href="https://arxiv.org/abs/2201.03110">Siddhant, et al., 2022</a>, explore the applications of adding <strong>M</strong>ore MASS to methods originally introduced by <a href="https://arxiv.org/abs/1905.02450">Song, et al., 2019</a> (emphasis mine, they don't have a fun backronym). On multilingual, semi-supervised NMT, state of the art generalization was reported across arbitrary language pairs by applying self-supervised denoising-autoencoder objectives to high-resource language datasets. Their complaint about the "unscalability" of data procurement for low-resource languages seems to be openly taking aim at <a href="https://arxiv.org/abs/2010.11125">M2M100</a>, introduced by Fan, et al., 2020.</p>
<blockquote>
<p>Achieving universal translation between all human language pairs is the holy-grail of machine translation (MT) research. While recent progress in massively multilingual MT is one step closer to reaching this goal, it is becoming evident that extending a multilingual MT system simply by training on more parallel data is unscalable, since the availability of labeled data for low-resource and non-English-centric language pairs is forbiddingly limited. To this end, we present a pragmatic approach towards building a multilingual MT model that covers hundreds of languages, <strong>using a mixture of supervised and self-supervised objectives, depending on the data availability for different language pairs.</strong> We demonstrate that the synergy between these two training paradigms enables the model to produce high-quality translations in the <strong>zero-resource setting,</strong> even surpassing supervised translation quality for low- and mid-resource languages. We conduct a wide array of experiments to understand the effect of the degree of multilingual supervision, domain mismatches and amounts of parallel and monolingual data on the quality of our self-supervised multilingual models. To demonstrate the scalability of the approach, we train models with <strong>over 200</strong> languages and demonstrate high performance on zero-resource translation on several previously under-studied languages. We hope our findings will serve as a stepping stone towards enabling translation for the next thousand languages.</p>
</blockquote></div></div><div style="padding-left:10px;padding-right:10px" class="ant-col ant-col-xs-0 ant-col-md-6"><div><div class=""><div class="ant-anchor-wrapper dendron-toc" style="max-height:calc(100vh - 64px);z-index:1"><div class="ant-anchor"><div class="ant-anchor-ink"><span class="ant-anchor-ink-ball"></span></div></div></div></div></div></div></div></div></div></main><div class="ant-divider ant-divider-horizontal" role="separator"></div><footer class="ant-layout-footer" style="padding:0 24px 24px"></footer></section></section></section></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"note":{"id":"epxo6h3psotasf3y7z98ect","title":"MMASS","desc":"","updated":1658950183377,"created":1658949602554,"custom":{},"fname":"ref.nlp.mass","type":"note","vault":{"fsPath":"vault"},"contentHash":"53d6b4c8e1c5bff2d25124d26ab49cac","links":[],"anchors":{},"children":[],"parent":"jlbuz8giyj93jsc1l0lmbzs","data":{}},"body":"\u003ch1 id=\"mmass\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#mmass\"\u003e\u003c/a\u003eMMASS\u003c/h1\u003e\n\u003cp\u003e\u003ca href=\"https://arxiv.org/abs/2201.03110\"\u003eSiddhant, et al., 2022\u003c/a\u003e, explore the applications of adding \u003cstrong\u003eM\u003c/strong\u003eore MASS to methods originally introduced by \u003ca href=\"https://arxiv.org/abs/1905.02450\"\u003eSong, et al., 2019\u003c/a\u003e (emphasis mine, they don't have a fun backronym). On multilingual, semi-supervised NMT, state of the art generalization was reported across arbitrary language pairs by applying self-supervised denoising-autoencoder objectives to high-resource language datasets. Their complaint about the \"unscalability\" of data procurement for low-resource languages seems to be openly taking aim at \u003ca href=\"https://arxiv.org/abs/2010.11125\"\u003eM2M100\u003c/a\u003e, introduced by Fan, et al., 2020.\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eAchieving universal translation between all human language pairs is the holy-grail of machine translation (MT) research. While recent progress in massively multilingual MT is one step closer to reaching this goal, it is becoming evident that extending a multilingual MT system simply by training on more parallel data is unscalable, since the availability of labeled data for low-resource and non-English-centric language pairs is forbiddingly limited. To this end, we present a pragmatic approach towards building a multilingual MT model that covers hundreds of languages, \u003cstrong\u003eusing a mixture of supervised and self-supervised objectives, depending on the data availability for different language pairs.\u003c/strong\u003e We demonstrate that the synergy between these two training paradigms enables the model to produce high-quality translations in the \u003cstrong\u003ezero-resource setting,\u003c/strong\u003e even surpassing supervised translation quality for low- and mid-resource languages. We conduct a wide array of experiments to understand the effect of the degree of multilingual supervision, domain mismatches and amounts of parallel and monolingual data on the quality of our self-supervised multilingual models. To demonstrate the scalability of the approach, we train models with \u003cstrong\u003eover 200\u003c/strong\u003e languages and demonstrate high performance on zero-resource translation on several previously under-studied languages. We hope our findings will serve as a stepping stone towards enabling translation for the next thousand languages.\u003c/p\u003e\n\u003c/blockquote\u003e","noteIndex":{"id":"ihfr21mlvz5lp3n62uu344t","title":"kavlogs","desc":"","updated":1659115143090,"created":1659018913792,"custom":{"nav_order":0,"permalink":"/"},"fname":"ref","type":"note","vault":{"fsPath":"vault"},"contentHash":"41b7e8cfe841b035025dfa85ec0b142e","links":[],"anchors":{},"children":["39acu8nb3xn6t18xul0ji8d","jc56h8njgqawadlroex4ju1","wf5gku64lj2ag6n8kzs9o8f","jlbuz8giyj93jsc1l0lmbzs","3c09ct2zvlk9dfitxexbss3"],"parent":null,"data":{},"body":"This is an assorted collection of notes and thoughts on things I've read about before. Here for my reference, and so that you can come here to read my background instead of receiving an untimely info-dump whose content just amounts to a recitation of anything here, out of mutual respect for my time and yours."},"collectionChildren":null,"customHeadContent":null,"config":{"version":5,"dev":{"enablePreviewV2":true,"enableSelfContainedVaults":true},"commands":{"lookup":{"note":{"selectionMode":"extract","confirmVaultOnCreate":true,"vaultSelectionModeOnCreate":"smart","leaveTrace":false,"bubbleUpCreateNew":true,"fuzzThreshold":0.2}},"randomNote":{},"insertNoteLink":{"aliasMode":"none","enableMultiSelect":false},"insertNoteIndex":{"enableMarker":false},"copyNoteLink":{},"templateHierarchy":"template"},"workspace":{"vaults":[{"fsPath":"vault"},{"fsPath":"projects"},{"fsPath":"tenets"}],"journal":{"dailyDomain":"daily","name":"journal","dateFormat":"y.MM.dd","addBehavior":"childOfDomain"},"scratch":{"name":"scratch","dateFormat":"y.MM.dd.HHmmss","addBehavior":"asOwnDomain"},"task":{"name":"task","dateFormat":"y.MM.dd","addBehavior":"asOwnDomain","statusSymbols":{"":" ","wip":"w","done":"x","assigned":"a","moved":"m","blocked":"b","delegated":"l","dropped":"d","pending":"y"},"taskCompleteStatus":["done","x"],"prioritySymbols":{"H":"high","M":"medium","L":"low"},"todoIntegration":false,"createTaskSelectionType":"selection2link"},"graph":{"zoomSpeed":1,"createStub":false},"enableAutoCreateOnDefinition":false,"enableHandlebarTemplates":true,"enableXVaultWikiLink":false,"enableRemoteVaultInit":true,"enableUserTags":true,"enableHashTags":true,"workspaceVaultSyncMode":"noCommit","enableAutoFoldFrontmatter":false,"enableEditorDecorations":true,"maxPreviewsCached":10,"maxNoteLength":204800,"enableFullHierarchyNoteTitle":false,"enableSmartRefs":true,"dendronVersion":"0.105.1"},"preview":{"enableFMTitle":true,"enableNoteTitleForLink":true,"enableFrontmatterTags":true,"enableHashesForFMTags":false,"enableMermaid":true,"enablePrettyRefs":true,"enableKatex":true,"automaticallyShowPreview":true},"publishing":{"theme":"dark","enableFMTitle":true,"enableNoteTitleForLink":true,"enableMermaid":true,"enablePrettyRefs":true,"enableKatex":true,"copyAssets":true,"siteUrl":"https://kavorite.github.io","assetsPrefix":"/vault","siteHierarchies":["ref","pub"],"writeStubs":false,"siteRootDir":"docs","seo":{"title":"⚑","description":"kavlogs"},"github":{"enableEditLink":false,"editBranch":"main","editViewMode":"tree","editLinkText":"Edit this page on GitHub"},"enableSiteLastModified":true,"enableFrontmatterTags":true,"enableHashesForFMTags":false,"enableRandomlyColoredTags":true,"enableTaskNotes":true,"enablePrettyLinks":true,"siteFaviconPath":"favicon.ico","siteIndex":"ref"}}},"__N_SSG":true},"page":"/notes/[id]","query":{"id":"epxo6h3psotasf3y7z98ect"},"buildId":"x67zoUTAB0zyGOxjfffun","assetPrefix":"/vault","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>