<!DOCTYPE html><html><head><meta name="viewport" content="width=device-width"/><meta charSet="utf-8"/><link rel="icon" href="/favicon.ico"/><title>Contrastive Language-Image Pretraining</title><meta name="robots" content="index,follow"/><meta name="googlebot" content="index,follow"/><meta name="description" content="kavlogs"/><meta property="og:title" content="Contrastive Language-Image Pretraining"/><meta property="og:description" content="kavlogs"/><meta property="og:url" content="https://kavorite.github.io/vault/notes/63z6zjmnp5tg1pj2rwcfb2f/"/><meta property="og:type" content="article"/><meta property="article:published_time" content="7/27/2022"/><meta property="article:modified_time" content="8/2/2022"/><link rel="canonical" href="https://kavorite.github.io/vault/notes/63z6zjmnp5tg1pj2rwcfb2f/"/><meta name="next-head-count" content="14"/><link rel="preload" href="/vault/_next/static/css/bec73badd4e5ba88.css" as="style"/><link rel="stylesheet" href="/vault/_next/static/css/bec73badd4e5ba88.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/vault/_next/static/chunks/polyfills-5cd94c89d3acac5f.js"></script><script src="/vault/_next/static/chunks/webpack-3af8c0cde089b23c.js" defer=""></script><script src="/vault/_next/static/chunks/framework-bb5c596eafb42b22.js" defer=""></script><script src="/vault/_next/static/chunks/main-34d019fcedb697b6.js" defer=""></script><script src="/vault/_next/static/chunks/pages/_app-b20c4be9bb651ea8.js" defer=""></script><script src="/vault/_next/static/chunks/826-e0e455fb469c158f.js" defer=""></script><script src="/vault/_next/static/chunks/986-737e5da213076068.js" defer=""></script><script src="/vault/_next/static/chunks/pages/notes/%5Bid%5D-00dd1421f3ce3a3e.js" defer=""></script><script src="/vault/_next/static/x67zoUTAB0zyGOxjfffun/_buildManifest.js" defer=""></script><script src="/vault/_next/static/x67zoUTAB0zyGOxjfffun/_ssgManifest.js" defer=""></script><script src="/vault/_next/static/x67zoUTAB0zyGOxjfffun/_middlewareManifest.js" defer=""></script></head><body><div id="__next" data-reactroot=""><section class="ant-layout" style="width:100%;min-height:100%"><header class="ant-layout-header" style="position:fixed;isolation:isolate;z-index:1;width:100%;border-bottom:1px solid #d4dadf;height:64px;padding:0 24px 0 2px"><div class="ant-row ant-row-center" style="max-width:992px;justify-content:space-between;margin:0 auto"><div style="display:flex" class="ant-col ant-col-xs-20 ant-col-sm-4"></div><div class="ant-col gutter-row ant-col-xs-0 ant-col-sm-20 ant-col-md-20 ant-col-lg-19"><div class="ant-select ant-select-lg ant-select-auto-complete ant-select-single ant-select-allow-clear ant-select-show-search" style="width:100%"><div class="ant-select-selector"><span class="ant-select-selection-search"><input type="search" autoComplete="off" class="ant-select-selection-search-input" role="combobox" aria-haspopup="listbox" aria-owns="undefined_list" aria-autocomplete="list" aria-controls="undefined_list" aria-activedescendant="undefined_list_0" value=""/></span><span class="ant-select-selection-placeholder">For full text search please use the &#x27;?&#x27; prefix. e.g. ? Onboarding</span></div></div></div><div style="display:none;align-items:center;justify-content:center" class="ant-col ant-col-xs-4 ant-col-sm-4 ant-col-md-0 ant-col-lg-0"><span role="img" aria-label="menu" style="font-size:24px" tabindex="-1" class="anticon anticon-menu"><svg viewBox="64 64 896 896" focusable="false" data-icon="menu" width="1em" height="1em" fill="currentColor" aria-hidden="true"><path d="M904 160H120c-4.4 0-8 3.6-8 8v64c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-64c0-4.4-3.6-8-8-8zm0 624H120c-4.4 0-8 3.6-8 8v64c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-64c0-4.4-3.6-8-8-8zm0-312H120c-4.4 0-8 3.6-8 8v64c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-64c0-4.4-3.6-8-8-8z"></path></svg></span></div></div></header><section class="ant-layout" style="margin-top:64px;display:flex;flex-direction:row"><div class="site-layout-sidebar" style="flex:0 0 auto;width:calc(max((100% - 992px) / 2, 0px) + 200px);min-width:200px;padding-left:calc((100% - 992px) / 2)"><aside class="ant-layout-sider ant-layout-sider-dark" style="position:fixed;overflow:auto;height:calc(100vh - 64px);background-color:transparent;flex:0 0 200px;max-width:200px;min-width:200px;width:200px"><div class="ant-layout-sider-children"></div></aside></div><section class="ant-layout side-layout-main" style="max-width:1200px;display:initial"><main class="ant-layout-content main-content" role="main" style="padding:0 24px"><div class="ant-row"><div class="ant-col ant-col-24"><div class="ant-row" style="margin-left:-10px;margin-right:-10px"><div style="padding-left:10px;padding-right:10px" class="ant-col ant-col-xs-24 ant-col-md-18"><div><h1 id="contrastive-language-image-pretraining"><a aria-hidden="true" class="anchor-heading icon-link" href="#contrastive-language-image-pretraining"></a>Contrastive Language-Image Pretraining</h1>
<p>Contrastive Language-Image Pretraining, or <a href="https://openai.com/blog/clip/">CLIP</a>, is a method which trains a language encoder jointly with an image decoder in a collaborative regime, distilling domain knowledge into an image encoder by using the language encoder's representations of image captions as a supervisory signal in a training regime almost identical to a parallel version of <a href="/vault/notes/9cismp3jsqbqx1pyso6xdc4">Supervised Contrastive Learning</a>. Unlike SCL and many related contrastive methods, CLIP has the distinction of embedding both input encoder representations into the same latent space, making it useful in multimodal modeling and conditioning generative applications on more than one type of support, as in <a href="https://openai.com/blog/dall-e/">Dall-E</a>'s unCLIP.</p>
<hr>
<strong>Backlinks</strong>
<ul>
<li><a href="/vault/notes/s2dvzt8effhbjxgsflxlw75">UnCLIP (vault)</a></li>
</ul></div></div><div style="padding-left:10px;padding-right:10px" class="ant-col ant-col-xs-0 ant-col-md-6"><div><div class=""><div class="ant-anchor-wrapper dendron-toc" style="max-height:calc(100vh - 64px);z-index:1"><div class="ant-anchor"><div class="ant-anchor-ink"><span class="ant-anchor-ink-ball"></span></div></div></div></div></div></div></div></div></div></main><div class="ant-divider ant-divider-horizontal" role="separator"></div><footer class="ant-layout-footer" style="padding:0 24px 24px"></footer></section></section></section></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"note":{"id":"63z6zjmnp5tg1pj2rwcfb2f","title":"Contrastive Language-Image Pretraining","desc":"","updated":1659409772664,"created":1658923754928,"custom":{},"fname":"ref.cl.clip","type":"note","vault":{"fsPath":"vault"},"contentHash":"0b91b639c5af6b5b8ec9470f19c9e092","links":[{"type":"wiki","from":{"fname":"ref.cl.clip","id":"63z6zjmnp5tg1pj2rwcfb2f","vaultName":"vault"},"value":"ref.cl.supcon","alias":"ref.cl.supcon","position":{"start":{"line":1,"column":356,"offset":355},"end":{"line":1,"column":373,"offset":372},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"ref.cl.supcon"}},{"from":{"fname":"ref.cv.unclip","vaultName":"vault"},"type":"backlink","position":{"start":{"line":2,"column":148,"offset":148},"end":{"line":2,"column":163,"offset":163},"indent":[]},"value":"ref.cl.clip","alias":"ref.cl.clip"}],"anchors":{},"children":[],"parent":"jc56h8njgqawadlroex4ju1","data":{}},"body":"\u003ch1 id=\"contrastive-language-image-pretraining\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#contrastive-language-image-pretraining\"\u003e\u003c/a\u003eContrastive Language-Image Pretraining\u003c/h1\u003e\n\u003cp\u003eContrastive Language-Image Pretraining, or \u003ca href=\"https://openai.com/blog/clip/\"\u003eCLIP\u003c/a\u003e, is a method which trains a language encoder jointly with an image decoder in a collaborative regime, distilling domain knowledge into an image encoder by using the language encoder's representations of image captions as a supervisory signal in a training regime almost identical to a parallel version of \u003ca href=\"/vault/notes/9cismp3jsqbqx1pyso6xdc4\"\u003eSupervised Contrastive Learning\u003c/a\u003e. Unlike SCL and many related contrastive methods, CLIP has the distinction of embedding both input encoder representations into the same latent space, making it useful in multimodal modeling and conditioning generative applications on more than one type of support, as in \u003ca href=\"https://openai.com/blog/dall-e/\"\u003eDall-E\u003c/a\u003e's unCLIP.\u003c/p\u003e\n\u003chr\u003e\n\u003cstrong\u003eBacklinks\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"/vault/notes/s2dvzt8effhbjxgsflxlw75\"\u003eUnCLIP (vault)\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e","noteIndex":{"id":"ihfr21mlvz5lp3n62uu344t","title":"kavlogs","desc":"","updated":1659115143090,"created":1659018913792,"custom":{"nav_order":0,"permalink":"/"},"fname":"ref","type":"note","vault":{"fsPath":"vault"},"contentHash":"41b7e8cfe841b035025dfa85ec0b142e","links":[],"anchors":{},"children":["39acu8nb3xn6t18xul0ji8d","jc56h8njgqawadlroex4ju1","wf5gku64lj2ag6n8kzs9o8f","jlbuz8giyj93jsc1l0lmbzs","3c09ct2zvlk9dfitxexbss3"],"parent":null,"data":{},"body":"This is an assorted collection of notes and thoughts on things I've read about before. Here for my reference, and so that you can come here to read my background instead of receiving an untimely info-dump whose content just amounts to a recitation of anything here, out of mutual respect for my time and yours."},"collectionChildren":null,"customHeadContent":null,"config":{"version":5,"dev":{"enablePreviewV2":true,"enableSelfContainedVaults":true},"commands":{"lookup":{"note":{"selectionMode":"extract","confirmVaultOnCreate":true,"vaultSelectionModeOnCreate":"smart","leaveTrace":false,"bubbleUpCreateNew":true,"fuzzThreshold":0.2}},"randomNote":{},"insertNoteLink":{"aliasMode":"none","enableMultiSelect":false},"insertNoteIndex":{"enableMarker":false},"copyNoteLink":{},"templateHierarchy":"template"},"workspace":{"vaults":[{"fsPath":"vault"},{"fsPath":"projects"},{"fsPath":"tenets"}],"journal":{"dailyDomain":"daily","name":"journal","dateFormat":"y.MM.dd","addBehavior":"childOfDomain"},"scratch":{"name":"scratch","dateFormat":"y.MM.dd.HHmmss","addBehavior":"asOwnDomain"},"task":{"name":"task","dateFormat":"y.MM.dd","addBehavior":"asOwnDomain","statusSymbols":{"":" ","wip":"w","done":"x","assigned":"a","moved":"m","blocked":"b","delegated":"l","dropped":"d","pending":"y"},"taskCompleteStatus":["done","x"],"prioritySymbols":{"H":"high","M":"medium","L":"low"},"todoIntegration":false,"createTaskSelectionType":"selection2link"},"graph":{"zoomSpeed":1,"createStub":false},"enableAutoCreateOnDefinition":false,"enableHandlebarTemplates":true,"enableXVaultWikiLink":false,"enableRemoteVaultInit":true,"enableUserTags":true,"enableHashTags":true,"workspaceVaultSyncMode":"noCommit","enableAutoFoldFrontmatter":false,"enableEditorDecorations":true,"maxPreviewsCached":10,"maxNoteLength":204800,"enableFullHierarchyNoteTitle":false,"enableSmartRefs":true,"dendronVersion":"0.105.1"},"preview":{"enableFMTitle":true,"enableNoteTitleForLink":true,"enableFrontmatterTags":true,"enableHashesForFMTags":false,"enableMermaid":true,"enablePrettyRefs":true,"enableKatex":true,"automaticallyShowPreview":true},"publishing":{"theme":"dark","enableFMTitle":true,"enableNoteTitleForLink":true,"enableMermaid":true,"enablePrettyRefs":true,"enableKatex":true,"copyAssets":true,"siteUrl":"https://kavorite.github.io","assetsPrefix":"/vault","siteHierarchies":["ref","pub"],"writeStubs":false,"siteRootDir":"docs","seo":{"title":"âš‘","description":"kavlogs"},"github":{"enableEditLink":false,"editBranch":"main","editViewMode":"tree","editLinkText":"Edit this page on GitHub"},"enableSiteLastModified":true,"enableFrontmatterTags":true,"enableHashesForFMTags":false,"enableRandomlyColoredTags":true,"enableTaskNotes":true,"enablePrettyLinks":true,"siteFaviconPath":"favicon.ico","siteIndex":"ref"}}},"__N_SSG":true},"page":"/notes/[id]","query":{"id":"63z6zjmnp5tg1pj2rwcfb2f"},"buildId":"x67zoUTAB0zyGOxjfffun","assetPrefix":"/vault","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>