<!DOCTYPE html><html><head><meta name="viewport" content="width=device-width"/><meta charSet="utf-8"/><link rel="icon" href="/favicon.ico"/><title>Hyperbolic Geometry</title><meta name="robots" content="index,follow"/><meta name="googlebot" content="index,follow"/><meta name="description" content="kavlogs"/><meta property="og:title" content="Hyperbolic Geometry"/><meta property="og:description" content="kavlogs"/><meta property="og:url" content="https://kavorite.github.io/vault/notes/ikhbh5ldwpxjjb3ev2aacu0/"/><meta property="og:type" content="article"/><meta property="article:published_time" content="7/26/2022"/><meta property="article:modified_time" content="7/28/2022"/><link rel="canonical" href="https://kavorite.github.io/vault/notes/ikhbh5ldwpxjjb3ev2aacu0/"/><meta name="next-head-count" content="14"/><link rel="preload" href="/vault/_next/static/css/bec73badd4e5ba88.css" as="style"/><link rel="stylesheet" href="/vault/_next/static/css/bec73badd4e5ba88.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/vault/_next/static/chunks/polyfills-5cd94c89d3acac5f.js"></script><script src="/vault/_next/static/chunks/webpack-3af8c0cde089b23c.js" defer=""></script><script src="/vault/_next/static/chunks/framework-bb5c596eafb42b22.js" defer=""></script><script src="/vault/_next/static/chunks/main-34d019fcedb697b6.js" defer=""></script><script src="/vault/_next/static/chunks/pages/_app-b20c4be9bb651ea8.js" defer=""></script><script src="/vault/_next/static/chunks/826-e0e455fb469c158f.js" defer=""></script><script src="/vault/_next/static/chunks/986-737e5da213076068.js" defer=""></script><script src="/vault/_next/static/chunks/pages/notes/%5Bid%5D-00dd1421f3ce3a3e.js" defer=""></script><script src="/vault/_next/static/x67zoUTAB0zyGOxjfffun/_buildManifest.js" defer=""></script><script src="/vault/_next/static/x67zoUTAB0zyGOxjfffun/_ssgManifest.js" defer=""></script><script src="/vault/_next/static/x67zoUTAB0zyGOxjfffun/_middlewareManifest.js" defer=""></script></head><body><div id="__next" data-reactroot=""><section class="ant-layout" style="width:100%;min-height:100%"><header class="ant-layout-header" style="position:fixed;isolation:isolate;z-index:1;width:100%;border-bottom:1px solid #d4dadf;height:64px;padding:0 24px 0 2px"><div class="ant-row ant-row-center" style="max-width:992px;justify-content:space-between;margin:0 auto"><div style="display:flex" class="ant-col ant-col-xs-20 ant-col-sm-4"></div><div class="ant-col gutter-row ant-col-xs-0 ant-col-sm-20 ant-col-md-20 ant-col-lg-19"><div class="ant-select ant-select-lg ant-select-auto-complete ant-select-single ant-select-allow-clear ant-select-show-search" style="width:100%"><div class="ant-select-selector"><span class="ant-select-selection-search"><input type="search" autoComplete="off" class="ant-select-selection-search-input" role="combobox" aria-haspopup="listbox" aria-owns="undefined_list" aria-autocomplete="list" aria-controls="undefined_list" aria-activedescendant="undefined_list_0" value=""/></span><span class="ant-select-selection-placeholder">For full text search please use the &#x27;?&#x27; prefix. e.g. ? Onboarding</span></div></div></div><div style="display:none;align-items:center;justify-content:center" class="ant-col ant-col-xs-4 ant-col-sm-4 ant-col-md-0 ant-col-lg-0"><span role="img" aria-label="menu" style="font-size:24px" tabindex="-1" class="anticon anticon-menu"><svg viewBox="64 64 896 896" focusable="false" data-icon="menu" width="1em" height="1em" fill="currentColor" aria-hidden="true"><path d="M904 160H120c-4.4 0-8 3.6-8 8v64c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-64c0-4.4-3.6-8-8-8zm0 624H120c-4.4 0-8 3.6-8 8v64c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-64c0-4.4-3.6-8-8-8zm0-312H120c-4.4 0-8 3.6-8 8v64c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-64c0-4.4-3.6-8-8-8z"></path></svg></span></div></div></header><section class="ant-layout" style="margin-top:64px;display:flex;flex-direction:row"><div class="site-layout-sidebar" style="flex:0 0 auto;width:calc(max((100% - 992px) / 2, 0px) + 200px);min-width:200px;padding-left:calc((100% - 992px) / 2)"><aside class="ant-layout-sider ant-layout-sider-dark" style="position:fixed;overflow:auto;height:calc(100vh - 64px);background-color:transparent;flex:0 0 200px;max-width:200px;min-width:200px;width:200px"><div class="ant-layout-sider-children"></div></aside></div><section class="ant-layout side-layout-main" style="max-width:1200px;display:initial"><main class="ant-layout-content main-content" role="main" style="padding:0 24px"><div class="ant-row"><div class="ant-col ant-col-24"><div class="ant-row" style="margin-left:-10px;margin-right:-10px"><div style="padding-left:10px;padding-right:10px" class="ant-col ant-col-xs-24 ant-col-md-18"><div><h1 id="hyperbolic-geometry"><a aria-hidden="true" class="anchor-heading icon-link" href="#hyperbolic-geometry"></a>Hyperbolic Geometry</h1>
<p>Hyperbolic geometry is highly useful for capturing semantic relationships between items. Particularly for domains with latent hierarchies: This can include word embeddings, and indeed, all other manner of graph embeddings. The ubiquity of applications was somewhat surprising to be considering the relative rarity of applied examples.</p>
<p>The main limitation of projecting latent embeddings onto the Riemannian manifold is the need for specialized gradient descent methods such as <a href="https://arxiv.org/abs/1806.03417">RSGD</a> (<a href="https://lars76.github.io/2020/07/23/rsgd-in-pytorch.html">tutorial</a>), which I suspect limits this method's accessibility by making it a little less "batteries-included" and sometimes incompatible with alternatives. Embedding latent representations with Hyperbolic metrics on a Poincaré ball can either be viewed as a blessing or a curse in practice, and its tradeoffs with Euclidean spaces are not always clear. But it's my opinion that most often, with data that fit exponential frequency distributions or adhere to explicit hierarchies as observed by <a href="https://arxiv.org/abs/1705.08039">Nickel, et al., 2017</a>, the additional representational capacity when working on a fixed compute budget and within a fixed dimensionality is well worth the cost.</p>
<p>In Euclidean geometry, because of the expectation that points are normally distributed, they must be clustered extremely tightly in order to form distinct groups (<a href="https://arxiv.org/abs/1804.03329">De Sa et al., 2018</a>). This is rather unfortunate for methods such as <a href="/vault/notes/9cismp3jsqbqx1pyso6xdc4">Supervised Contrastive Learning</a>, which rely explicitly on a small selection of samples having strong positive relationships, and everything else tending to be embedded very far away because of the ease with which clusters emerge on the Poincaré unit sphere as compared with the Euclidean unit sphere. <a href="https://arxiv.org/abs/1904.02239v2">Some research</a> suggests that this is not always practical. A small distance between hyperbolic embeddings on a unit Poincaré sphere captures not one, but two semantic properties: </p>
<ol>
<li>"betweenness" of an item with in a hierarchy, and</li>
<li>the "subtree" to which the item belongs.</li>
</ol>
<p>Following is a graphic depicting the learning of Euclidean word embeddings.</p>
<p><img src="/vault/assets/images/euclidean.webp" alt="Euclidean word embeddings"></p>
<p>Notice how deviating from the origin quickly forces subspaces to the edges of the unit sphere. This pattern requires far fewer dimensions to capture using hyperbolic geometry to distance neighborhoods from one another on a hyperbolic sphere, because it allows distances between neighborhoods to be defined by their centrality <em>with respect to the origin.</em> Contrast below.</p>
<p><img src="/vault/assets/images/hyperbolic.webp" alt="Hyperbolic word embeddings"></p>
<p>This means hyperbolic geometry allows for more efficient embedding of latent hierarchies, which is reflective of many long-tailed frequency distributions. Natural language corpora, for example, contain latent hierarchies, because "chinchilla" is a type of "mammal." Controlling for this property is important in a variety of information retrieval applications, most notably <a href="https://tfidf.com">bag-of-words document vectorization</a>.</p>
<p><img src="/vault/assets/images/word_frequency.png" alt="English word frequencies"></p>
<p>Certain publications have gotten around this by using bespoke loss functions to explicitly model the hierarchy of labels (e.g., for <a href="https://arxiv.org/abs/2104.10972">ImageNet pretraining</a>), but that takes a lot of effort: and it only encapsulates the hierarchies that are imposed by engineers, which doesn't allow models to efficiently <em>learn</em> latent hierarchies from supervisory signals that may contain many latent hierarchical relationships, yet explicitly offer explicit insight into very few by way of supervisory signals. Hyperbolic embeddings are not just a way to regularize a somewhat noisy solution space, but also a promising approach to allowing our optimizers more degrees of freedom in designing good solutions, taking the effort of imposing hierarchical domain models for symbolic data through explicit use of "SynSets" out of our own hands.</p>
<hr>
<strong>Backlinks</strong>
<ul>
<li><a href="/vault/notes/jc56h8njgqawadlroex4ju1">Contrastive Learning (vault)</a></li>
<li><a href="/vault/notes/9cismp3jsqbqx1pyso6xdc4">Supervised Contrastive Learning (vault)</a></li>
</ul></div></div><div style="padding-left:10px;padding-right:10px" class="ant-col ant-col-xs-0 ant-col-md-6"><div><div class=""><div class="ant-anchor-wrapper dendron-toc" style="max-height:calc(100vh - 64px);z-index:1"><div class="ant-anchor"><div class="ant-anchor-ink"><span class="ant-anchor-ink-ball"></span></div></div></div></div></div></div></div></div></div></main><div class="ant-divider ant-divider-horizontal" role="separator"></div><footer class="ant-layout-footer" style="padding:0 24px 24px"></footer></section></section></section></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"note":{"id":"ikhbh5ldwpxjjb3ev2aacu0","title":"Hyperbolic Geometry","desc":"","updated":1659019753675,"created":1658836812312,"custom":{},"fname":"ref.opt.hyperbolics","type":"note","vault":{"fsPath":"vault"},"contentHash":"6a34dac5a71f7d339460f55ef69514e2","links":[{"type":"wiki","from":{"fname":"ref.opt.hyperbolics","id":"ikhbh5ldwpxjjb3ev2aacu0","vaultName":"vault"},"value":"ref.cl.supcon","alias":"ref.cl.supcon","position":{"start":{"line":5,"column":245,"offset":1406},"end":{"line":5,"column":262,"offset":1423},"indent":[]},"xvault":false,"sameFile":false,"to":{"fname":"ref.cl.supcon"}},{"from":{"fname":"ref.cl","vaultName":"vault"},"type":"backlink","position":{"start":{"line":13,"column":206,"offset":1919},"end":{"line":13,"column":253,"offset":1966},"indent":[]},"value":"ref.opt.hyperbolics","alias":"the Riemannian manifold"},{"from":{"fname":"ref.cl.supcon","vaultName":"vault"},"type":"backlink","position":{"start":{"line":6,"column":378,"offset":1400},"end":{"line":6,"column":415,"offset":1437},"indent":[]},"value":"ref.opt.hyperbolics","alias":"Poincaré ball"}],"anchors":{},"children":[],"parent":"3c09ct2zvlk9dfitxexbss3","data":{}},"body":"\u003ch1 id=\"hyperbolic-geometry\"\u003e\u003ca aria-hidden=\"true\" class=\"anchor-heading icon-link\" href=\"#hyperbolic-geometry\"\u003e\u003c/a\u003eHyperbolic Geometry\u003c/h1\u003e\n\u003cp\u003eHyperbolic geometry is highly useful for capturing semantic relationships between items. Particularly for domains with latent hierarchies: This can include word embeddings, and indeed, all other manner of graph embeddings. The ubiquity of applications was somewhat surprising to be considering the relative rarity of applied examples.\u003c/p\u003e\n\u003cp\u003eThe main limitation of projecting latent embeddings onto the Riemannian manifold is the need for specialized gradient descent methods such as \u003ca href=\"https://arxiv.org/abs/1806.03417\"\u003eRSGD\u003c/a\u003e (\u003ca href=\"https://lars76.github.io/2020/07/23/rsgd-in-pytorch.html\"\u003etutorial\u003c/a\u003e), which I suspect limits this method's accessibility by making it a little less \"batteries-included\" and sometimes incompatible with alternatives. Embedding latent representations with Hyperbolic metrics on a Poincaré ball can either be viewed as a blessing or a curse in practice, and its tradeoffs with Euclidean spaces are not always clear. But it's my opinion that most often, with data that fit exponential frequency distributions or adhere to explicit hierarchies as observed by \u003ca href=\"https://arxiv.org/abs/1705.08039\"\u003eNickel, et al., 2017\u003c/a\u003e, the additional representational capacity when working on a fixed compute budget and within a fixed dimensionality is well worth the cost.\u003c/p\u003e\n\u003cp\u003eIn Euclidean geometry, because of the expectation that points are normally distributed, they must be clustered extremely tightly in order to form distinct groups (\u003ca href=\"https://arxiv.org/abs/1804.03329\"\u003eDe Sa et al., 2018\u003c/a\u003e). This is rather unfortunate for methods such as \u003ca href=\"/vault/notes/9cismp3jsqbqx1pyso6xdc4\"\u003eSupervised Contrastive Learning\u003c/a\u003e, which rely explicitly on a small selection of samples having strong positive relationships, and everything else tending to be embedded very far away because of the ease with which clusters emerge on the Poincaré unit sphere as compared with the Euclidean unit sphere. \u003ca href=\"https://arxiv.org/abs/1904.02239v2\"\u003eSome research\u003c/a\u003e suggests that this is not always practical. A small distance between hyperbolic embeddings on a unit Poincaré sphere captures not one, but two semantic properties: \u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\"betweenness\" of an item with in a hierarchy, and\u003c/li\u003e\n\u003cli\u003ethe \"subtree\" to which the item belongs.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003eFollowing is a graphic depicting the learning of Euclidean word embeddings.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/vault/assets/images/euclidean.webp\" alt=\"Euclidean word embeddings\"\u003e\u003c/p\u003e\n\u003cp\u003eNotice how deviating from the origin quickly forces subspaces to the edges of the unit sphere. This pattern requires far fewer dimensions to capture using hyperbolic geometry to distance neighborhoods from one another on a hyperbolic sphere, because it allows distances between neighborhoods to be defined by their centrality \u003cem\u003ewith respect to the origin.\u003c/em\u003e Contrast below.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/vault/assets/images/hyperbolic.webp\" alt=\"Hyperbolic word embeddings\"\u003e\u003c/p\u003e\n\u003cp\u003eThis means hyperbolic geometry allows for more efficient embedding of latent hierarchies, which is reflective of many long-tailed frequency distributions. Natural language corpora, for example, contain latent hierarchies, because \"chinchilla\" is a type of \"mammal.\" Controlling for this property is important in a variety of information retrieval applications, most notably \u003ca href=\"https://tfidf.com\"\u003ebag-of-words document vectorization\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/vault/assets/images/word_frequency.png\" alt=\"English word frequencies\"\u003e\u003c/p\u003e\n\u003cp\u003eCertain publications have gotten around this by using bespoke loss functions to explicitly model the hierarchy of labels (e.g., for \u003ca href=\"https://arxiv.org/abs/2104.10972\"\u003eImageNet pretraining\u003c/a\u003e), but that takes a lot of effort: and it only encapsulates the hierarchies that are imposed by engineers, which doesn't allow models to efficiently \u003cem\u003elearn\u003c/em\u003e latent hierarchies from supervisory signals that may contain many latent hierarchical relationships, yet explicitly offer explicit insight into very few by way of supervisory signals. Hyperbolic embeddings are not just a way to regularize a somewhat noisy solution space, but also a promising approach to allowing our optimizers more degrees of freedom in designing good solutions, taking the effort of imposing hierarchical domain models for symbolic data through explicit use of \"SynSets\" out of our own hands.\u003c/p\u003e\n\u003chr\u003e\n\u003cstrong\u003eBacklinks\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"/vault/notes/jc56h8njgqawadlroex4ju1\"\u003eContrastive Learning (vault)\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/vault/notes/9cismp3jsqbqx1pyso6xdc4\"\u003eSupervised Contrastive Learning (vault)\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e","noteIndex":{"id":"ihfr21mlvz5lp3n62uu344t","title":"kavlogs","desc":"","updated":1659115143090,"created":1659018913792,"custom":{"nav_order":0,"permalink":"/"},"fname":"ref","type":"note","vault":{"fsPath":"vault"},"contentHash":"41b7e8cfe841b035025dfa85ec0b142e","links":[],"anchors":{},"children":["39acu8nb3xn6t18xul0ji8d","jc56h8njgqawadlroex4ju1","wf5gku64lj2ag6n8kzs9o8f","jlbuz8giyj93jsc1l0lmbzs","3c09ct2zvlk9dfitxexbss3"],"parent":null,"data":{},"body":"This is an assorted collection of notes and thoughts on things I've read about before. Here for my reference, and so that you can come here to read my background instead of receiving an untimely info-dump whose content just amounts to a recitation of anything here, out of mutual respect for my time and yours."},"collectionChildren":null,"customHeadContent":null,"config":{"version":5,"dev":{"enablePreviewV2":true,"enableSelfContainedVaults":true},"commands":{"lookup":{"note":{"selectionMode":"extract","confirmVaultOnCreate":true,"vaultSelectionModeOnCreate":"smart","leaveTrace":false,"bubbleUpCreateNew":true,"fuzzThreshold":0.2}},"randomNote":{},"insertNoteLink":{"aliasMode":"none","enableMultiSelect":false},"insertNoteIndex":{"enableMarker":false},"copyNoteLink":{},"templateHierarchy":"template"},"workspace":{"vaults":[{"fsPath":"vault"},{"fsPath":"projects"},{"fsPath":"tenets"}],"journal":{"dailyDomain":"daily","name":"journal","dateFormat":"y.MM.dd","addBehavior":"childOfDomain"},"scratch":{"name":"scratch","dateFormat":"y.MM.dd.HHmmss","addBehavior":"asOwnDomain"},"task":{"name":"task","dateFormat":"y.MM.dd","addBehavior":"asOwnDomain","statusSymbols":{"":" ","wip":"w","done":"x","assigned":"a","moved":"m","blocked":"b","delegated":"l","dropped":"d","pending":"y"},"taskCompleteStatus":["done","x"],"prioritySymbols":{"H":"high","M":"medium","L":"low"},"todoIntegration":false,"createTaskSelectionType":"selection2link"},"graph":{"zoomSpeed":1,"createStub":false},"enableAutoCreateOnDefinition":false,"enableHandlebarTemplates":true,"enableXVaultWikiLink":false,"enableRemoteVaultInit":true,"enableUserTags":true,"enableHashTags":true,"workspaceVaultSyncMode":"noCommit","enableAutoFoldFrontmatter":false,"enableEditorDecorations":true,"maxPreviewsCached":10,"maxNoteLength":204800,"enableFullHierarchyNoteTitle":false,"enableSmartRefs":true,"dendronVersion":"0.105.1"},"preview":{"enableFMTitle":true,"enableNoteTitleForLink":true,"enableFrontmatterTags":true,"enableHashesForFMTags":false,"enableMermaid":true,"enablePrettyRefs":true,"enableKatex":true,"automaticallyShowPreview":true},"publishing":{"theme":"dark","enableFMTitle":true,"enableNoteTitleForLink":true,"enableMermaid":true,"enablePrettyRefs":true,"enableKatex":true,"copyAssets":true,"siteUrl":"https://kavorite.github.io","assetsPrefix":"/vault","siteHierarchies":["ref","pub"],"writeStubs":false,"siteRootDir":"docs","seo":{"title":"⚑","description":"kavlogs"},"github":{"enableEditLink":false,"editBranch":"main","editViewMode":"tree","editLinkText":"Edit this page on GitHub"},"enableSiteLastModified":true,"enableFrontmatterTags":true,"enableHashesForFMTags":false,"enableRandomlyColoredTags":true,"enableTaskNotes":true,"enablePrettyLinks":true,"siteFaviconPath":"favicon.ico","siteIndex":"ref"}}},"__N_SSG":true},"page":"/notes/[id]","query":{"id":"ikhbh5ldwpxjjb3ev2aacu0"},"buildId":"x67zoUTAB0zyGOxjfffun","assetPrefix":"/vault","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>